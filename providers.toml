# cliProxyAPI 聚合网关配置 (物理实例 + 逻辑路由)

[global]
host = "0.0.0.0"
main_port = 8145                 # 主聚合端口
proxy = "http://127.0.0.1:10808"
request_retry = 3                # 实例内自动重试（403/5xx 等）
max_retry_interval = 30          # 最长等待冷却秒数
lb_auth_cooldown_ms = 1800000    # LB 认证类错误冷却 30 分钟
lb_max_target_retries = 1        # LB 首包前最多自动切换重试次数

# ==========================================
# 1. 物理实例定义 (Instances)
#    每个 [instances.name] 对应一个独立进程
# ==========================================

# --- 实例 A: Official (官方原生 Auth 聚合) ---
# 包含 Antigravity (Google) 和 OpenAI (Codex/ChatGPT)
# 均使用 OAuth 登录，无需在此填 Key
[instances.official]
port = 8146
providers = [
  # 1. Antigravity (Google OAuth)
  # 需运行: ./cliproxy --antigravity-login
  { type = "antigravity", rotation_strategy = "round-robin" },

  # 2. OpenAI Official (Codex/ChatGPT OAuth)
  # 需运行: ./cliproxy --codex-login
  { type = "codex", rotation_strategy = "round-robin" },
]

# --- 实例 B: Zenmux (聚合渠道 - API Key) ---
[instances.zenmux]
port = 8147
disable_cooling = true
providers = [
  # Endpoint 1: OpenAI 兼容 (GPT, DeepSeek, Kimi)
  { type = "openai", base_url = "https://zenmux.ai/api/v1", api_keys = [
    "${ZENMUX_KEY}",
  ] },
  # Endpoint 2: Anthropic 兼容 (Claude)
  { type = "anthropic", base_url = "https://zenmux.ai/api/anthropic", api_keys = [
    "${ZENMUX_KEY}",
  ] },
  # Endpoint 3: Vertex AI 兼容 (Gemini)
  { type = "gemini", base_url = "https://zenmux.ai/api/vertex-ai", api_keys = [
    "${ZENMUX_KEY}",
  ] },
]

# ==========================================
# 2. 聚合路由与映射 (Routing)
#    定义主网关对外暴露的模型，以及分发策略
#    格式: "对外ID" = [ { instance="实例名", provider="逻辑Provider类型", model="内部映射名", weight=权重 }, ... ]
# ==========================================

[routing]

"opus4.6" = [
  { instance = "official", provider = "antigravity", model = "claude-opus-4-6-thinking", weight = 80 },
  { instance = "zenmux", provider = "anthropic", model = "anthropic/claude-opus-4.6", weight = 20 },
]

"g3p" = [
  { instance = "official", provider = "antigravity", model = "gemini-3-pro-high", weight = 999 },
  { instance = "zenmux", provider = "openai", model = "google/gemini-3-pro-preview", weight = 1, params = { "reasoning_effort" = "high" } },
]

"g3f" = [
  { instance = "official", provider = "antigravity", model = "gemini-3-flash", weight = 999 },
  { instance = "zenmux", provider = "openai", model = "google/gemini-3-flash-preview", weight = 1 },
]

"g3i" = [
  { instance = "official", provider = "antigravity", model = "gemini-3-pro-image", weight = 999 },
  { instance = "zenmux", provider = "gemini", model = "google/gemini-3-pro-image-preview", weight = 1 },
]

"gpt5.3" = [
  { instance = "official", provider = "codex", model = "gpt-5.3-codex", weight = 1, params = { "reasoning_effort" = "high" } },
]

"gpt5.2" = [
  { instance = "official", provider = "codex", model = "gpt-5.2", weight = 80, params = { "reasoning_effort" = "high" } },
  { instance = "zenmux", provider = "openai", model = "openai/gpt-5.2", weight = 20, params = { "reasoning_effort" = "high" } },
]
